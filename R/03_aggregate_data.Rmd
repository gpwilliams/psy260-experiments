---
title: "Aggregate Data"
output: html_notebook
---

We will first install the pacman package if it is not already installed. This makes loading packages easier to do. Next, we will load the tidyverse and here packages for our data filtering.

# Optionally Install Packages, Load Packages

```{r load-packages}
if(!require("pacman")) {install.packages("pacman")}
pacman::p_load("tidyverse", "here")
```

# Load Data

We will load up our tidied data from the data folder just as in 01_clean-data.Rmd and 02_filter-data.Rmd.

```{r message = FALSE}
tidied_data <- read_csv(here("data", "tidied_data.csv"))
```

# Make Data Aggregated by Participants

We will make by-participant averages of some measures of performance in the study. To do this, we will take our data and group it by each participant (under the response_id column) and the condition they are in. Then we will make our averages for each participant.

## Accuracy Data

Here we will group our data by the participant (response_id) and their conditions (congruency). We will then make a data set which has their response ID in it, a count of how many trials went into their responses, and the number of correct responses they gave. 

This is calculated by taking the sum of the TRUE/FALSE values in the correct column. However, we can't sum up Boolean (TRUE/FALSE) data, so we first make this numeric. In R, TRUE defaults to 1, and FALSE defaults to 0, so we essentially only sum up all of the correct responses (i.e. how many 1s did we find?).

```{r make-accuracy-data, message = FALSE}
accuracy_data <- tidied_data %>% 
  drop_na(correct) %>% 
  group_by(response_id, congruency, concreteness) %>% 
  summarise(
    n = n(),
    mean_correct = sum(as.numeric(correct))
  )
```

## Reaction Time Data

Here we will find out how quickly participants responded to trials that were congruent or incongruent in terms of the sentence direction and response direction. 

We will first only keep responses where they got the trial correct. After that, we will group the data by the participant (response_id) and their conditions (congruency). Finally, we will get a count of how many trials they got correct and then take an average (mean) of their duration on that trial. This count of duration stops when a response is made.

We could be even smarter here by filtering out any trials where reaction times were exceptionally long. Imagine we want to remove reaction times that are at or greater than 2000ms (i.e. 2 seconds) long. To do this, just change the filter code to read `filter(correct == TRUE, duration < 2000)`

```{r make-rt-data, message = FALSE}
response_time_data <- tidied_data %>% 
  filter(correct == 1) %>% 
  drop_na(duration) %>% 
  group_by(response_id, congruency, concreteness) %>% 
  summarise(
    n = n(),
    mean_rt = mean(duration)
  )
```

# Save Data

Finally, we will save our two data sets separately in the data folder as accuracy_data.csv and response_time_data.csv. Our data is now ready for analysis using R, JASP, Jamovi, or even SPSS.

```{r save-summaries}
write_csv(accuracy_data, here("data", "accuracy_data.csv"))
write_csv(response_time_data, here("data", "response_time_data.csv"))
```

